{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4767d277-4414-4179-bff0-00d8ab87ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file:///C:/Users/Kyle/Downloads/Supervised%20Learning%20Rubric.pdf\n",
    "# https://www.basketball-reference.com/teams/LAL/2025/gamelog/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc9fdf",
   "metadata": {},
   "source": [
    "Will the lakers win their next game? Logistic Regression on 24-25 season\n",
    "\n",
    "Problem:\n",
    "\n",
    "How does the lakers currently perform this season? How well will the lakers perform against different teams this season? How well will the lakers perform in the next game? All of these questions can be answered using this logistic regression model that predicts whether or not the lakers will win when evaluating features related to the game. This model can be used by fans to determine whether or not it is worth it to go watch the next game or for analytics teams to determine how their team is performing and how they would perform in theoretical situations. Since this model is predicting the outcome of the game win or loss, it is a classification problem and will use the logistic regression model to predict outcomes.\n",
    "\n",
    "Exploratory Data Analysis (EDA) procedure:\n",
    "\n",
    "Since the model that will be used is logistic regression, an ROC curve will be used to evaluate the model's true positive rate vs the false positive rate. Other metrics that will also be evaluated are precision and recall of the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a2d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555e927",
   "metadata": {},
   "source": [
    "About the Data:\n",
    "\n",
    "All data were collected from basketball-reference.com in the form of tabulated data. Basketball Reference is a public source that provides up to date nba statistics. Since the project is only aiming to predict the performance of the current laker's team this season, only 24/82 games were played so far meaning the data has 24 entries. However there are many features per entry including: stats about the lakers and their opponent each game. There are about 37 features in this dataset. The first three features are all categorical features such as the location, outcome and opponent team. The rest of the features are numeric about how the team and the opponent played such as points, steals, turnovers, etc.\n",
    "\n",
    "Collecting and Cleaning Data:\n",
    "\n",
    "To collect the data I visited basketball-reference.com and selected the advanced game log data of each game from the current 2024-25 season. There was an option to download a csv so I downloaded it and formatted it on a spreadsheet. There were a few issues with the dataset. One issue was that some features were not relevant so those were dropped, namely the dates and game count. The second issue was that some categorical data were strings and needed to be encoded, these were the home/away, win/lose, opponent team features. The first two features were easily cleaned and replaced in the spread sheet software, but encoding the teams was done to the pandas data frame in the import function below. Numbers were assigned to each team to keep track of them for the model to train. The third issue was empty columns which were easily removed in the spreadsheet software. The fourth issue was that there were collinear features. Using a correlation matrix, I was able to spot some collinear features with high correlation so I removed one of the features to remove the collinearity.\n",
    "\n",
    "Conclusions and Discussion:\n",
    "\n",
    "To conclude, the cleaning process was removing irrelevant features, data munging, removing empty columns, and removing collinear features. There were not any missing values as all games have statistics so no rows were dropped. Since the target variable is whether or not the lakers will win or not based on the other features, this problem seems to be a classification problem and can be done well using logistic regression. In total the data frame after cleaning is 24 rows and 28 features.\n",
    "\n",
    "Basketball Reference. (n.d.). 2024-25 Los Angeles Lakers team game log. Basketball. https://www.basketball-reference.com/teams/LAL/2025/gamelog/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc73b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Opp</th>\n",
       "      <th>W/L</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Opp.1</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTopp</th>\n",
       "      <th>FTAopp</th>\n",
       "      <th>FT%opp</th>\n",
       "      <th>ORBopp</th>\n",
       "      <th>TRBopp</th>\n",
       "      <th>ASTopp</th>\n",
       "      <th>STLopp</th>\n",
       "      <th>BLKopp</th>\n",
       "      <th>TOVopp</th>\n",
       "      <th>PFopp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142881</td>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.139568</td>\n",
       "      <td>0.299217</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.355459</td>\n",
       "      <td>0.123231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473831</td>\n",
       "      <td>0.500664</td>\n",
       "      <td>0.120899</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>0.235409</td>\n",
       "      <td>0.246714</td>\n",
       "      <td>0.036551</td>\n",
       "      <td>0.367851</td>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.094726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opp</th>\n",
       "      <td>0.142881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.271455</td>\n",
       "      <td>0.451682</td>\n",
       "      <td>0.170489</td>\n",
       "      <td>0.129878</td>\n",
       "      <td>0.329628</td>\n",
       "      <td>0.084992</td>\n",
       "      <td>0.046824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.118252</td>\n",
       "      <td>0.454752</td>\n",
       "      <td>0.082557</td>\n",
       "      <td>0.406297</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.426352</td>\n",
       "      <td>0.011366</td>\n",
       "      <td>0.118507</td>\n",
       "      <td>0.066028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W/L</th>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527133</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.409243</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.512282</td>\n",
       "      <td>0.280529</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389440</td>\n",
       "      <td>0.353410</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.470817</td>\n",
       "      <td>0.270912</td>\n",
       "      <td>0.429475</td>\n",
       "      <td>0.176633</td>\n",
       "      <td>0.113197</td>\n",
       "      <td>0.047363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm</th>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.271455</td>\n",
       "      <td>0.527133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.239681</td>\n",
       "      <td>0.858609</td>\n",
       "      <td>0.281138</td>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.640990</td>\n",
       "      <td>0.183580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472093</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.366237</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.469821</td>\n",
       "      <td>0.191250</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.160978</td>\n",
       "      <td>0.124103</td>\n",
       "      <td>0.472563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opp.1</th>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.451682</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.239681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174093</td>\n",
       "      <td>0.154742</td>\n",
       "      <td>0.081815</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.106696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262129</td>\n",
       "      <td>0.236947</td>\n",
       "      <td>0.260483</td>\n",
       "      <td>0.286656</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>0.793045</td>\n",
       "      <td>0.471883</td>\n",
       "      <td>0.155644</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.292020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG</th>\n",
       "      <td>0.139568</td>\n",
       "      <td>0.170489</td>\n",
       "      <td>0.409243</td>\n",
       "      <td>0.858609</td>\n",
       "      <td>0.174093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575537</td>\n",
       "      <td>0.719060</td>\n",
       "      <td>0.559177</td>\n",
       "      <td>0.179897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445757</td>\n",
       "      <td>0.411783</td>\n",
       "      <td>0.279942</td>\n",
       "      <td>0.026456</td>\n",
       "      <td>0.349030</td>\n",
       "      <td>0.207665</td>\n",
       "      <td>0.154554</td>\n",
       "      <td>0.162807</td>\n",
       "      <td>0.200143</td>\n",
       "      <td>0.119019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGA</th>\n",
       "      <td>0.299217</td>\n",
       "      <td>0.129878</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.281138</td>\n",
       "      <td>0.154742</td>\n",
       "      <td>0.575537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150639</td>\n",
       "      <td>0.142410</td>\n",
       "      <td>0.217136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312177</td>\n",
       "      <td>0.357576</td>\n",
       "      <td>0.039421</td>\n",
       "      <td>0.125260</td>\n",
       "      <td>0.261241</td>\n",
       "      <td>0.030723</td>\n",
       "      <td>0.346037</td>\n",
       "      <td>0.464106</td>\n",
       "      <td>0.201552</td>\n",
       "      <td>0.105660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG%</th>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.329628</td>\n",
       "      <td>0.512282</td>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.081815</td>\n",
       "      <td>0.719060</td>\n",
       "      <td>0.150639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282810</td>\n",
       "      <td>0.203676</td>\n",
       "      <td>0.306423</td>\n",
       "      <td>0.143353</td>\n",
       "      <td>0.642516</td>\n",
       "      <td>0.213405</td>\n",
       "      <td>0.082877</td>\n",
       "      <td>0.187840</td>\n",
       "      <td>0.083097</td>\n",
       "      <td>0.256339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P</th>\n",
       "      <td>0.355459</td>\n",
       "      <td>0.084992</td>\n",
       "      <td>0.280529</td>\n",
       "      <td>0.640990</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.559177</td>\n",
       "      <td>0.142410</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.549813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634068</td>\n",
       "      <td>0.600340</td>\n",
       "      <td>0.368856</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>0.195691</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>0.051343</td>\n",
       "      <td>0.367385</td>\n",
       "      <td>0.084936</td>\n",
       "      <td>0.081340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3PA</th>\n",
       "      <td>0.123231</td>\n",
       "      <td>0.046824</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>0.183580</td>\n",
       "      <td>0.106696</td>\n",
       "      <td>0.179897</td>\n",
       "      <td>0.217136</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>0.549813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440715</td>\n",
       "      <td>0.487067</td>\n",
       "      <td>0.097934</td>\n",
       "      <td>0.155146</td>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.259013</td>\n",
       "      <td>0.172220</td>\n",
       "      <td>0.097886</td>\n",
       "      <td>0.147251</td>\n",
       "      <td>0.248031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P%</th>\n",
       "      <td>0.350567</td>\n",
       "      <td>0.178955</td>\n",
       "      <td>0.284909</td>\n",
       "      <td>0.656153</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.544483</td>\n",
       "      <td>0.019141</td>\n",
       "      <td>0.654468</td>\n",
       "      <td>0.883640</td>\n",
       "      <td>0.112594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496948</td>\n",
       "      <td>0.420983</td>\n",
       "      <td>0.422088</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.266750</td>\n",
       "      <td>0.089524</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>0.372892</td>\n",
       "      <td>0.030148</td>\n",
       "      <td>0.240377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>0.141233</td>\n",
       "      <td>0.278607</td>\n",
       "      <td>0.361908</td>\n",
       "      <td>0.505770</td>\n",
       "      <td>0.232873</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.302566</td>\n",
       "      <td>0.357130</td>\n",
       "      <td>0.043830</td>\n",
       "      <td>0.199221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>0.102231</td>\n",
       "      <td>0.152560</td>\n",
       "      <td>0.082265</td>\n",
       "      <td>0.377362</td>\n",
       "      <td>0.121181</td>\n",
       "      <td>0.090112</td>\n",
       "      <td>0.112502</td>\n",
       "      <td>0.071442</td>\n",
       "      <td>0.773999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTA</th>\n",
       "      <td>0.197120</td>\n",
       "      <td>0.247131</td>\n",
       "      <td>0.286482</td>\n",
       "      <td>0.441882</td>\n",
       "      <td>0.247193</td>\n",
       "      <td>0.024598</td>\n",
       "      <td>0.394836</td>\n",
       "      <td>0.337216</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.224147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026258</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.171249</td>\n",
       "      <td>0.062556</td>\n",
       "      <td>0.321904</td>\n",
       "      <td>0.112892</td>\n",
       "      <td>0.018889</td>\n",
       "      <td>0.094403</td>\n",
       "      <td>0.056579</td>\n",
       "      <td>0.809948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT%</th>\n",
       "      <td>0.118224</td>\n",
       "      <td>0.157642</td>\n",
       "      <td>0.378061</td>\n",
       "      <td>0.351741</td>\n",
       "      <td>0.133246</td>\n",
       "      <td>0.502840</td>\n",
       "      <td>0.333969</td>\n",
       "      <td>0.304650</td>\n",
       "      <td>0.034693</td>\n",
       "      <td>0.136153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025937</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>0.059630</td>\n",
       "      <td>0.076135</td>\n",
       "      <td>0.283609</td>\n",
       "      <td>0.021677</td>\n",
       "      <td>0.236679</td>\n",
       "      <td>0.103190</td>\n",
       "      <td>0.017594</td>\n",
       "      <td>0.249772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORB</th>\n",
       "      <td>0.166479</td>\n",
       "      <td>0.188973</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0.123339</td>\n",
       "      <td>0.359946</td>\n",
       "      <td>0.059445</td>\n",
       "      <td>0.467955</td>\n",
       "      <td>0.318848</td>\n",
       "      <td>0.264672</td>\n",
       "      <td>0.062753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233290</td>\n",
       "      <td>0.187453</td>\n",
       "      <td>0.198560</td>\n",
       "      <td>0.254611</td>\n",
       "      <td>0.104335</td>\n",
       "      <td>0.317256</td>\n",
       "      <td>0.222071</td>\n",
       "      <td>0.147883</td>\n",
       "      <td>0.240775</td>\n",
       "      <td>0.231551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRB</th>\n",
       "      <td>0.110494</td>\n",
       "      <td>0.214383</td>\n",
       "      <td>0.264225</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.402294</td>\n",
       "      <td>0.105632</td>\n",
       "      <td>0.235565</td>\n",
       "      <td>0.088598</td>\n",
       "      <td>0.049592</td>\n",
       "      <td>0.163430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182003</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.198487</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.122152</td>\n",
       "      <td>0.439080</td>\n",
       "      <td>0.040804</td>\n",
       "      <td>0.337315</td>\n",
       "      <td>0.550764</td>\n",
       "      <td>0.285866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0.216552</td>\n",
       "      <td>0.190030</td>\n",
       "      <td>0.377419</td>\n",
       "      <td>0.647194</td>\n",
       "      <td>0.203968</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.104625</td>\n",
       "      <td>0.617412</td>\n",
       "      <td>0.543184</td>\n",
       "      <td>0.049893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277593</td>\n",
       "      <td>0.208457</td>\n",
       "      <td>0.301618</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>0.322236</td>\n",
       "      <td>0.293152</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.143991</td>\n",
       "      <td>0.050298</td>\n",
       "      <td>0.145386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STL</th>\n",
       "      <td>0.081379</td>\n",
       "      <td>0.086269</td>\n",
       "      <td>0.112381</td>\n",
       "      <td>0.054160</td>\n",
       "      <td>0.091842</td>\n",
       "      <td>0.061612</td>\n",
       "      <td>0.139185</td>\n",
       "      <td>0.041689</td>\n",
       "      <td>0.069373</td>\n",
       "      <td>0.069750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104647</td>\n",
       "      <td>0.046241</td>\n",
       "      <td>0.160149</td>\n",
       "      <td>0.132239</td>\n",
       "      <td>0.091594</td>\n",
       "      <td>0.102319</td>\n",
       "      <td>0.177230</td>\n",
       "      <td>0.193070</td>\n",
       "      <td>0.721053</td>\n",
       "      <td>0.003749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLK</th>\n",
       "      <td>0.389542</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.200301</td>\n",
       "      <td>0.224283</td>\n",
       "      <td>0.209382</td>\n",
       "      <td>0.313012</td>\n",
       "      <td>0.179998</td>\n",
       "      <td>0.225537</td>\n",
       "      <td>0.296577</td>\n",
       "      <td>0.039025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210893</td>\n",
       "      <td>0.276874</td>\n",
       "      <td>0.022897</td>\n",
       "      <td>0.158924</td>\n",
       "      <td>0.124981</td>\n",
       "      <td>0.133758</td>\n",
       "      <td>0.165389</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>0.230288</td>\n",
       "      <td>0.072527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOV</th>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.458356</td>\n",
       "      <td>0.352810</td>\n",
       "      <td>0.139981</td>\n",
       "      <td>0.393030</td>\n",
       "      <td>0.164352</td>\n",
       "      <td>0.364232</td>\n",
       "      <td>0.080193</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>0.058480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097866</td>\n",
       "      <td>0.115251</td>\n",
       "      <td>0.079871</td>\n",
       "      <td>0.347461</td>\n",
       "      <td>0.297931</td>\n",
       "      <td>0.335897</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>0.046635</td>\n",
       "      <td>0.244638</td>\n",
       "      <td>0.047253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>0.381625</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>0.242852</td>\n",
       "      <td>0.343462</td>\n",
       "      <td>0.235417</td>\n",
       "      <td>0.326257</td>\n",
       "      <td>0.326146</td>\n",
       "      <td>0.115684</td>\n",
       "      <td>0.476909</td>\n",
       "      <td>0.387742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717917</td>\n",
       "      <td>0.737851</td>\n",
       "      <td>0.310547</td>\n",
       "      <td>0.042779</td>\n",
       "      <td>0.054667</td>\n",
       "      <td>0.386245</td>\n",
       "      <td>0.239134</td>\n",
       "      <td>0.176868</td>\n",
       "      <td>0.195685</td>\n",
       "      <td>0.157768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGopp</th>\n",
       "      <td>0.356627</td>\n",
       "      <td>0.378525</td>\n",
       "      <td>0.518730</td>\n",
       "      <td>0.085841</td>\n",
       "      <td>0.933018</td>\n",
       "      <td>0.017234</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.025021</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>0.228265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532351</td>\n",
       "      <td>0.497389</td>\n",
       "      <td>0.375255</td>\n",
       "      <td>0.258322</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.784252</td>\n",
       "      <td>0.423640</td>\n",
       "      <td>0.069762</td>\n",
       "      <td>0.156898</td>\n",
       "      <td>0.300245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGAopp</th>\n",
       "      <td>0.266281</td>\n",
       "      <td>0.204622</td>\n",
       "      <td>0.301517</td>\n",
       "      <td>0.276984</td>\n",
       "      <td>0.534330</td>\n",
       "      <td>0.150355</td>\n",
       "      <td>0.067130</td>\n",
       "      <td>0.112781</td>\n",
       "      <td>0.065051</td>\n",
       "      <td>0.040083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218036</td>\n",
       "      <td>0.222591</td>\n",
       "      <td>0.054453</td>\n",
       "      <td>0.284216</td>\n",
       "      <td>0.177743</td>\n",
       "      <td>0.291222</td>\n",
       "      <td>0.202587</td>\n",
       "      <td>0.211478</td>\n",
       "      <td>0.556505</td>\n",
       "      <td>0.320958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG%opp</th>\n",
       "      <td>0.238473</td>\n",
       "      <td>0.332466</td>\n",
       "      <td>0.446027</td>\n",
       "      <td>0.095972</td>\n",
       "      <td>0.794460</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>0.047960</td>\n",
       "      <td>0.113930</td>\n",
       "      <td>0.226565</td>\n",
       "      <td>0.256032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517539</td>\n",
       "      <td>0.459165</td>\n",
       "      <td>0.454648</td>\n",
       "      <td>0.524715</td>\n",
       "      <td>0.101211</td>\n",
       "      <td>0.788420</td>\n",
       "      <td>0.385387</td>\n",
       "      <td>0.058115</td>\n",
       "      <td>0.187102</td>\n",
       "      <td>0.136159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Popp</th>\n",
       "      <td>0.230351</td>\n",
       "      <td>0.296770</td>\n",
       "      <td>0.378507</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.603779</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>0.064337</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.231386</td>\n",
       "      <td>0.218699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515636</td>\n",
       "      <td>0.465827</td>\n",
       "      <td>0.392960</td>\n",
       "      <td>0.405354</td>\n",
       "      <td>0.101028</td>\n",
       "      <td>0.723729</td>\n",
       "      <td>0.474705</td>\n",
       "      <td>0.028453</td>\n",
       "      <td>0.120063</td>\n",
       "      <td>0.296517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3PAopp</th>\n",
       "      <td>0.142050</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.113184</td>\n",
       "      <td>0.022750</td>\n",
       "      <td>0.287481</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.079952</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>0.302644</td>\n",
       "      <td>0.475816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401620</td>\n",
       "      <td>0.414287</td>\n",
       "      <td>0.177029</td>\n",
       "      <td>0.283396</td>\n",
       "      <td>0.187162</td>\n",
       "      <td>0.304053</td>\n",
       "      <td>0.386121</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.309685</td>\n",
       "      <td>0.245484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3P%opp</th>\n",
       "      <td>0.164690</td>\n",
       "      <td>0.427580</td>\n",
       "      <td>0.395825</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.563511</td>\n",
       "      <td>0.056298</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>0.097024</td>\n",
       "      <td>0.059617</td>\n",
       "      <td>0.101489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365690</td>\n",
       "      <td>0.282677</td>\n",
       "      <td>0.390877</td>\n",
       "      <td>0.371875</td>\n",
       "      <td>0.042130</td>\n",
       "      <td>0.698870</td>\n",
       "      <td>0.343387</td>\n",
       "      <td>0.081929</td>\n",
       "      <td>0.364059</td>\n",
       "      <td>0.238343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTopp</th>\n",
       "      <td>0.473831</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.389440</td>\n",
       "      <td>0.472093</td>\n",
       "      <td>0.262129</td>\n",
       "      <td>0.445757</td>\n",
       "      <td>0.312177</td>\n",
       "      <td>0.282810</td>\n",
       "      <td>0.634068</td>\n",
       "      <td>0.440715</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942410</td>\n",
       "      <td>0.544892</td>\n",
       "      <td>0.211649</td>\n",
       "      <td>0.052517</td>\n",
       "      <td>0.480745</td>\n",
       "      <td>0.213314</td>\n",
       "      <td>0.222968</td>\n",
       "      <td>0.295162</td>\n",
       "      <td>0.179368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTAopp</th>\n",
       "      <td>0.500664</td>\n",
       "      <td>0.118252</td>\n",
       "      <td>0.353410</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.236947</td>\n",
       "      <td>0.411783</td>\n",
       "      <td>0.357576</td>\n",
       "      <td>0.203676</td>\n",
       "      <td>0.600340</td>\n",
       "      <td>0.487067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.246522</td>\n",
       "      <td>0.249137</td>\n",
       "      <td>0.060645</td>\n",
       "      <td>0.447513</td>\n",
       "      <td>0.242926</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.270307</td>\n",
       "      <td>0.106858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT%opp</th>\n",
       "      <td>0.120899</td>\n",
       "      <td>0.454752</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>0.366237</td>\n",
       "      <td>0.260483</td>\n",
       "      <td>0.279942</td>\n",
       "      <td>0.039421</td>\n",
       "      <td>0.306423</td>\n",
       "      <td>0.368856</td>\n",
       "      <td>0.097934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544892</td>\n",
       "      <td>0.246522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.251451</td>\n",
       "      <td>0.330086</td>\n",
       "      <td>0.137213</td>\n",
       "      <td>0.269052</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.193468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORBopp</th>\n",
       "      <td>0.046122</td>\n",
       "      <td>0.082557</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.286656</td>\n",
       "      <td>0.026456</td>\n",
       "      <td>0.125260</td>\n",
       "      <td>0.143353</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>0.155146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211649</td>\n",
       "      <td>0.249137</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672903</td>\n",
       "      <td>0.354643</td>\n",
       "      <td>0.323612</td>\n",
       "      <td>0.116638</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>0.042686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRBopp</th>\n",
       "      <td>0.235409</td>\n",
       "      <td>0.406297</td>\n",
       "      <td>0.470817</td>\n",
       "      <td>0.469821</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>0.349030</td>\n",
       "      <td>0.261241</td>\n",
       "      <td>0.642516</td>\n",
       "      <td>0.195691</td>\n",
       "      <td>0.046256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052517</td>\n",
       "      <td>0.060645</td>\n",
       "      <td>0.251451</td>\n",
       "      <td>0.672903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224558</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.131155</td>\n",
       "      <td>0.083584</td>\n",
       "      <td>0.124184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASTopp</th>\n",
       "      <td>0.246714</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.270912</td>\n",
       "      <td>0.191250</td>\n",
       "      <td>0.793045</td>\n",
       "      <td>0.207665</td>\n",
       "      <td>0.030723</td>\n",
       "      <td>0.213405</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>0.259013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480745</td>\n",
       "      <td>0.447513</td>\n",
       "      <td>0.330086</td>\n",
       "      <td>0.354643</td>\n",
       "      <td>0.224558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428237</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>0.085239</td>\n",
       "      <td>0.139969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STLopp</th>\n",
       "      <td>0.036551</td>\n",
       "      <td>0.426352</td>\n",
       "      <td>0.429475</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.471883</td>\n",
       "      <td>0.154554</td>\n",
       "      <td>0.346037</td>\n",
       "      <td>0.082877</td>\n",
       "      <td>0.051343</td>\n",
       "      <td>0.172220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213314</td>\n",
       "      <td>0.242926</td>\n",
       "      <td>0.137213</td>\n",
       "      <td>0.323612</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.428237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042350</td>\n",
       "      <td>0.234832</td>\n",
       "      <td>0.012157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLKopp</th>\n",
       "      <td>0.367851</td>\n",
       "      <td>0.011366</td>\n",
       "      <td>0.176633</td>\n",
       "      <td>0.160978</td>\n",
       "      <td>0.155644</td>\n",
       "      <td>0.162807</td>\n",
       "      <td>0.464106</td>\n",
       "      <td>0.187840</td>\n",
       "      <td>0.367385</td>\n",
       "      <td>0.097886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222968</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.269052</td>\n",
       "      <td>0.116638</td>\n",
       "      <td>0.131155</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>0.042350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243111</td>\n",
       "      <td>0.090939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOVopp</th>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.118507</td>\n",
       "      <td>0.113197</td>\n",
       "      <td>0.124103</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.200143</td>\n",
       "      <td>0.201552</td>\n",
       "      <td>0.083097</td>\n",
       "      <td>0.084936</td>\n",
       "      <td>0.147251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295162</td>\n",
       "      <td>0.270307</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>0.083584</td>\n",
       "      <td>0.085239</td>\n",
       "      <td>0.234832</td>\n",
       "      <td>0.243111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFopp</th>\n",
       "      <td>0.094726</td>\n",
       "      <td>0.066028</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0.472563</td>\n",
       "      <td>0.292020</td>\n",
       "      <td>0.119019</td>\n",
       "      <td>0.105660</td>\n",
       "      <td>0.256339</td>\n",
       "      <td>0.081340</td>\n",
       "      <td>0.248031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179368</td>\n",
       "      <td>0.106858</td>\n",
       "      <td>0.193468</td>\n",
       "      <td>0.042686</td>\n",
       "      <td>0.124184</td>\n",
       "      <td>0.139969</td>\n",
       "      <td>0.012157</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Location       Opp       W/L        Tm     Opp.1        FG  \\\n",
       "Location  1.000000  0.142881  0.342657  0.263171  0.225050  0.139568   \n",
       "Opp       0.142881  1.000000  0.641900  0.271455  0.451682  0.170489   \n",
       "W/L       0.342657  0.641900  1.000000  0.527133  0.465800  0.409243   \n",
       "Tm        0.263171  0.271455  0.527133  1.000000  0.239681  0.858609   \n",
       "Opp.1     0.225050  0.451682  0.465800  0.239681  1.000000  0.174093   \n",
       "FG        0.139568  0.170489  0.409243  0.858609  0.174093  1.000000   \n",
       "FGA       0.299217  0.129878  0.002184  0.281138  0.154742  0.575537   \n",
       "FG%       0.433470  0.329628  0.512282  0.812625  0.081815  0.719060   \n",
       "3P        0.355459  0.084992  0.280529  0.640990  0.042173  0.559177   \n",
       "3PA       0.123231  0.046824  0.098189  0.183580  0.106696  0.179897   \n",
       "3P%       0.350567  0.178955  0.284909  0.656153  0.067372  0.544483   \n",
       "FT        0.141233  0.278607  0.361908  0.505770  0.232873  0.061212   \n",
       "FTA       0.197120  0.247131  0.286482  0.441882  0.247193  0.024598   \n",
       "FT%       0.118224  0.157642  0.378061  0.351741  0.133246  0.502840   \n",
       "ORB       0.166479  0.188973  0.277466  0.123339  0.359946  0.059445   \n",
       "TRB       0.110494  0.214383  0.264225  0.009592  0.402294  0.105632   \n",
       "AST       0.216552  0.190030  0.377419  0.647194  0.203968  0.583942   \n",
       "STL       0.081379  0.086269  0.112381  0.054160  0.091842  0.061612   \n",
       "BLK       0.389542  0.108300  0.200301  0.224283  0.209382  0.313012   \n",
       "TOV       0.010946  0.458356  0.352810  0.139981  0.393030  0.164352   \n",
       "PF        0.381625  0.029624  0.242852  0.343462  0.235417  0.326257   \n",
       "FGopp     0.356627  0.378525  0.518730  0.085841  0.933018  0.017234   \n",
       "FGAopp    0.266281  0.204622  0.301517  0.276984  0.534330  0.150355   \n",
       "FG%opp    0.238473  0.332466  0.446027  0.095972  0.794460  0.134610   \n",
       "3Popp     0.230351  0.296770  0.378507  0.157000  0.603779  0.014074   \n",
       "3PAopp    0.142050  0.078067  0.113184  0.022750  0.287481  0.142100   \n",
       "3P%opp    0.164690  0.427580  0.395825  0.170400  0.563511  0.056298   \n",
       "FTopp     0.473831  0.032275  0.389440  0.472093  0.262129  0.445757   \n",
       "FTAopp    0.500664  0.118252  0.353410  0.399400  0.236947  0.411783   \n",
       "FT%opp    0.120899  0.454752  0.284114  0.366237  0.260483  0.279942   \n",
       "ORBopp    0.046122  0.082557  0.022058  0.031954  0.286656  0.026456   \n",
       "TRBopp    0.235409  0.406297  0.470817  0.469821  0.039360  0.349030   \n",
       "ASTopp    0.246714  0.254265  0.270912  0.191250  0.793045  0.207665   \n",
       "STLopp    0.036551  0.426352  0.429475  0.161100  0.471883  0.154554   \n",
       "BLKopp    0.367851  0.011366  0.176633  0.160978  0.155644  0.162807   \n",
       "TOVopp    0.194885  0.118507  0.113197  0.124103  0.000873  0.200143   \n",
       "PFopp     0.094726  0.066028  0.047363  0.472563  0.292020  0.119019   \n",
       "\n",
       "               FGA       FG%        3P       3PA  ...     FTopp    FTAopp  \\\n",
       "Location  0.299217  0.433470  0.355459  0.123231  ...  0.473831  0.500664   \n",
       "Opp       0.129878  0.329628  0.084992  0.046824  ...  0.032275  0.118252   \n",
       "W/L       0.002184  0.512282  0.280529  0.098189  ...  0.389440  0.353410   \n",
       "Tm        0.281138  0.812625  0.640990  0.183580  ...  0.472093  0.399400   \n",
       "Opp.1     0.154742  0.081815  0.042173  0.106696  ...  0.262129  0.236947   \n",
       "FG        0.575537  0.719060  0.559177  0.179897  ...  0.445757  0.411783   \n",
       "FGA       1.000000  0.150639  0.142410  0.217136  ...  0.312177  0.357576   \n",
       "FG%       0.150639  1.000000  0.560669  0.026178  ...  0.282810  0.203676   \n",
       "3P        0.142410  0.560669  1.000000  0.549813  ...  0.634068  0.600340   \n",
       "3PA       0.217136  0.026178  0.549813  1.000000  ...  0.440715  0.487067   \n",
       "3P%       0.019141  0.654468  0.883640  0.112594  ...  0.496948  0.420983   \n",
       "FT        0.302566  0.357130  0.043830  0.199221  ...  0.017899  0.102231   \n",
       "FTA       0.394836  0.337216  0.002404  0.224147  ...  0.026258  0.060879   \n",
       "FT%       0.333969  0.304650  0.034693  0.136153  ...  0.025937  0.037323   \n",
       "ORB       0.467955  0.318848  0.264672  0.062753  ...  0.233290  0.187453   \n",
       "TRB       0.235565  0.088598  0.049592  0.163430  ...  0.182003  0.156800   \n",
       "AST       0.104625  0.617412  0.543184  0.049893  ...  0.277593  0.208457   \n",
       "STL       0.139185  0.041689  0.069373  0.069750  ...  0.104647  0.046241   \n",
       "BLK       0.179998  0.225537  0.296577  0.039025  ...  0.210893  0.276874   \n",
       "TOV       0.364232  0.080193  0.099575  0.058480  ...  0.097866  0.115251   \n",
       "PF        0.326146  0.115684  0.476909  0.387742  ...  0.717917  0.737851   \n",
       "FGopp     0.005063  0.025021  0.157352  0.228265  ...  0.532351  0.497389   \n",
       "FGAopp    0.067130  0.112781  0.065051  0.040083  ...  0.218036  0.222591   \n",
       "FG%opp    0.047960  0.113930  0.226565  0.256032  ...  0.517539  0.459165   \n",
       "3Popp     0.064337  0.041635  0.231386  0.218699  ...  0.515636  0.465827   \n",
       "3PAopp    0.079952  0.090599  0.302644  0.475816  ...  0.401620  0.414287   \n",
       "3P%opp    0.037963  0.097024  0.059617  0.101489  ...  0.365690  0.282677   \n",
       "FTopp     0.312177  0.282810  0.634068  0.440715  ...  1.000000  0.942410   \n",
       "FTAopp    0.357576  0.203676  0.600340  0.487067  ...  0.942410  1.000000   \n",
       "FT%opp    0.039421  0.306423  0.368856  0.097934  ...  0.544892  0.246522   \n",
       "ORBopp    0.125260  0.143353  0.086733  0.155146  ...  0.211649  0.249137   \n",
       "TRBopp    0.261241  0.642516  0.195691  0.046256  ...  0.052517  0.060645   \n",
       "ASTopp    0.030723  0.213405  0.018628  0.259013  ...  0.480745  0.447513   \n",
       "STLopp    0.346037  0.082877  0.051343  0.172220  ...  0.213314  0.242926   \n",
       "BLKopp    0.464106  0.187840  0.367385  0.097886  ...  0.222968  0.143317   \n",
       "TOVopp    0.201552  0.083097  0.084936  0.147251  ...  0.295162  0.270307   \n",
       "PFopp     0.105660  0.256339  0.081340  0.248031  ...  0.179368  0.106858   \n",
       "\n",
       "            FT%opp    ORBopp    TRBopp    ASTopp    STLopp    BLKopp  \\\n",
       "Location  0.120899  0.046122  0.235409  0.246714  0.036551  0.367851   \n",
       "Opp       0.454752  0.082557  0.406297  0.254265  0.426352  0.011366   \n",
       "W/L       0.284114  0.022058  0.470817  0.270912  0.429475  0.176633   \n",
       "Tm        0.366237  0.031954  0.469821  0.191250  0.161100  0.160978   \n",
       "Opp.1     0.260483  0.286656  0.039360  0.793045  0.471883  0.155644   \n",
       "FG        0.279942  0.026456  0.349030  0.207665  0.154554  0.162807   \n",
       "FGA       0.039421  0.125260  0.261241  0.030723  0.346037  0.464106   \n",
       "FG%       0.306423  0.143353  0.642516  0.213405  0.082877  0.187840   \n",
       "3P        0.368856  0.086733  0.195691  0.018628  0.051343  0.367385   \n",
       "3PA       0.097934  0.155146  0.046256  0.259013  0.172220  0.097886   \n",
       "3P%       0.422088  0.009334  0.266750  0.089524  0.014511  0.372892   \n",
       "FT        0.152560  0.082265  0.377362  0.121181  0.090112  0.112502   \n",
       "FTA       0.171249  0.062556  0.321904  0.112892  0.018889  0.094403   \n",
       "FT%       0.059630  0.076135  0.283609  0.021677  0.236679  0.103190   \n",
       "ORB       0.198560  0.254611  0.104335  0.317256  0.222071  0.147883   \n",
       "TRB       0.198487  0.092300  0.122152  0.439080  0.040804  0.337315   \n",
       "AST       0.301618  0.056015  0.322236  0.293152  0.026564  0.143991   \n",
       "STL       0.160149  0.132239  0.091594  0.102319  0.177230  0.193070   \n",
       "BLK       0.022897  0.158924  0.124981  0.133758  0.165389  0.036164   \n",
       "TOV       0.079871  0.347461  0.297931  0.335897  0.870321  0.046635   \n",
       "PF        0.310547  0.042779  0.054667  0.386245  0.239134  0.176868   \n",
       "FGopp     0.375255  0.258322  0.011611  0.784252  0.423640  0.069762   \n",
       "FGAopp    0.054453  0.284216  0.177743  0.291222  0.202587  0.211478   \n",
       "FG%opp    0.454648  0.524715  0.101211  0.788420  0.385387  0.058115   \n",
       "3Popp     0.392960  0.405354  0.101028  0.723729  0.474705  0.028453   \n",
       "3PAopp    0.177029  0.283396  0.187162  0.304053  0.386121  0.039254   \n",
       "3P%opp    0.390877  0.371875  0.042130  0.698870  0.343387  0.081929   \n",
       "FTopp     0.544892  0.211649  0.052517  0.480745  0.213314  0.222968   \n",
       "FTAopp    0.246522  0.249137  0.060645  0.447513  0.242926  0.143317   \n",
       "FT%opp    1.000000  0.050368  0.251451  0.330086  0.137213  0.269052   \n",
       "ORBopp    0.050368  1.000000  0.672903  0.354643  0.323612  0.116638   \n",
       "TRBopp    0.251451  0.672903  1.000000  0.224558  0.263430  0.131155   \n",
       "ASTopp    0.330086  0.354643  0.224558  1.000000  0.428237  0.017675   \n",
       "STLopp    0.137213  0.323612  0.263430  0.428237  1.000000  0.042350   \n",
       "BLKopp    0.269052  0.116638  0.131155  0.017675  0.042350  1.000000   \n",
       "TOVopp    0.137833  0.031791  0.083584  0.085239  0.234832  0.243111   \n",
       "PFopp     0.193468  0.042686  0.124184  0.139969  0.012157  0.090939   \n",
       "\n",
       "            TOVopp     PFopp  \n",
       "Location  0.194885  0.094726  \n",
       "Opp       0.118507  0.066028  \n",
       "W/L       0.113197  0.047363  \n",
       "Tm        0.124103  0.472563  \n",
       "Opp.1     0.000873  0.292020  \n",
       "FG        0.200143  0.119019  \n",
       "FGA       0.201552  0.105660  \n",
       "FG%       0.083097  0.256339  \n",
       "3P        0.084936  0.081340  \n",
       "3PA       0.147251  0.248031  \n",
       "3P%       0.030148  0.240377  \n",
       "FT        0.071442  0.773999  \n",
       "FTA       0.056579  0.809948  \n",
       "FT%       0.017594  0.249772  \n",
       "ORB       0.240775  0.231551  \n",
       "TRB       0.550764  0.285866  \n",
       "AST       0.050298  0.145386  \n",
       "STL       0.721053  0.003749  \n",
       "BLK       0.230288  0.072527  \n",
       "TOV       0.244638  0.047253  \n",
       "PF        0.195685  0.157768  \n",
       "FGopp     0.156898  0.300245  \n",
       "FGAopp    0.556505  0.320958  \n",
       "FG%opp    0.187102  0.136159  \n",
       "3Popp     0.120063  0.296517  \n",
       "3PAopp    0.309685  0.245484  \n",
       "3P%opp    0.364059  0.238343  \n",
       "FTopp     0.295162  0.179368  \n",
       "FTAopp    0.270307  0.106858  \n",
       "FT%opp    0.137833  0.193468  \n",
       "ORBopp    0.031791  0.042686  \n",
       "TRBopp    0.083584  0.124184  \n",
       "ASTopp    0.085239  0.139969  \n",
       "STLopp    0.234832  0.012157  \n",
       "BLKopp    0.243111  0.090939  \n",
       "TOVopp    1.000000  0.066618  \n",
       "PFopp     0.066618  1.000000  \n",
       "\n",
       "[37 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class data_import:\n",
    "\n",
    "    def __init__(self):\n",
    "        df = pd.read_csv(\"../laker_data.csv\")\n",
    "        \n",
    "        # encode the opponent teams into numbers\n",
    "        encoder = LabelEncoder()\n",
    "        team_labels = encoder.fit_transform(df[\"Opp\"])\n",
    "        df[\"Opp\"] = team_labels\n",
    "        \n",
    "        y = df[\"W/L\"].values\n",
    "        # dropping collinear features in x\n",
    "        x = df.drop([\"W/L\", \"FG\", \"FGopp\", \"3P\", \"3Popp\", \"FT\", \"FTopp\", \"STLopp\", \"PFopp\"], axis=1).values\n",
    "\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "        self.df = df\n",
    "\n",
    "data = data_import()\n",
    "data.df.corr().abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58639f-f7cb-409b-8cef-7298c34cea81",
   "metadata": {},
   "source": [
    "Building Logistic Regression Model\n",
    "\n",
    "Hyperparameter Tuning:\n",
    "\n",
    "Chose to use liblinear as the solver for the LogisticRegression model because it is recommended for smaller datasets, my dataset only has 24 samples so it would be considered small. Random state to a random value to shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0730b2b5-bfe8-4254-90b7-4f5538e4b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver=\"liblinear\" ,random_state=10).fit(data.train_x, data.train_y) # liblinear solver is best used for smaller datasets like mine\n",
    "\n",
    "yp = clf.predict(data.test_x)\n",
    "ypp = clf.predict_proba(data.test_x) # the probabilities of predicting outcome label as win or loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf9b57-968c-4c67-92e1-6fdce19bc31e",
   "metadata": {},
   "source": [
    "Plotting the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672c6849-1eac-4ad0-aa27-befb6113e15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.7, 0.2, 'AUC=0.833')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, th = roc_curve(data.test_y,ypp[:,1])\n",
    "auc = roc_auc_score(data.test_y,ypp[:,1])\n",
    "plt.plot(fpr,tpr,\"k-\")\n",
    "plt.plot(np.arange(0,1.1,0.1), np.arange(0,1.1,0.1), \"r--\")\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.text(0.7, 0.2,\"AUC=\" + \"{:.3f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4063cc4b-89c1-4961-b816-94818baa566f",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "The red line represents the random guess. The curve seems to be 2 right angles, one at just under 0.7 and one that peaks at 1.0. The area under the curve (AUC) is also at 0.833. What this curve shows us is that the the true positive rate is around 0.65 and the false positive rate is around 0.35 until the true positive rate is at 1.0 which is when the false positive rate is at 0.0. The curve has a relatively large AUC indicating a good performance from the model to distinguish between wins and losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa29cb-a24b-433a-b54e-58e6c49549ef",
   "metadata": {},
   "source": [
    "Calculate Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aa77b8-5431-4b9a-8baa-6392c92d708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Precision :  1.0\n",
      "Model Recall :  0.6666666666666666\n",
      "y true:  [1 0 1 0 1]\n",
      "y prediction:  [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision(y_true, y_pred):\n",
    "    # true positive divided by true and false positives\n",
    "    n = len(y_true)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(n):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1: # check for true positive\n",
    "            tp += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 1: # check for false positive\n",
    "            fp += 1\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def calculate_recall(y_true, y_pred):\n",
    "    # true positive divided by true positive and false negatives\n",
    "    n = len(y_true)\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for i in range(n):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1: # check for true positive\n",
    "            tp += 1\n",
    "        elif y_true[i] == 1 and y_pred[i] == 0: # check for false negative\n",
    "            fn += 1\n",
    "    \n",
    "    return tp/(tp + fn)\n",
    "\n",
    "precision = calculate_precision(data.test_y, yp)\n",
    "recall = calculate_recall(data.test_y, yp)\n",
    "print('Model Precision : ' , precision)\n",
    "print('Model Recall : ' , recall)\n",
    "print(\"y true: \", data.test_y)\n",
    "print(\"y prediction: \", yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5ddd9-c60c-4a8f-abfe-237a208f29d3",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "The precision of the model at 1.0 means that for all the positive values it predicted they are all correct. In this context positive means a win for the lakers. This is true if we look at the y-true and y-prediction, each win or 1 value in the prediction list is also 1 in the y-true list. In other words, the model's prediction of 1 (win) values are always correct. Do not get confused about the 0 (lose) values, those can be wrong as precision does not measure those.\n",
    "\n",
    "The recall of the model at 0.666 means that for all the positive values in the actual list, the model only correctly predicted 66.6% of them correctly. This can be seem when comparing the y-true and y-prediction lists, at the first index of the y-prediction list it incorrectly predicts a loss when it should have been a win for the lakers, the rest of the win predictions (1 in the list) seem to match the y-true list. In other words, the model's percentage of correctly predicting a win is only 66.6% of the time. Sometimes the model will predict a loss when in reality it was a win."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012346f-88aa-4e89-8cd8-9c752c8d177a",
   "metadata": {},
   "source": [
    "Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab206bf0-efae-4419-a794-8769031914c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    correct = 0\n",
    "    for i in range(n):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / n\n",
    "\n",
    "accuracy = calculate_accuracy(data.test_y, yp)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a5cb9-92ed-4547-95b9-d3917c1cdd0f",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "The accuracy is 0.8 or 80% meaning that the logistic regression model correctly predicts the outcome of the games 80% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b867b77d-bdee-42d0-8a2f-fb0022f168ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.78238877e-01 2.21761123e-01]\n",
      " [9.99758293e-01 2.41707151e-04]\n",
      " [9.12716707e-02 9.08728329e-01]\n",
      " [7.32553123e-01 2.67446877e-01]\n",
      " [5.98741555e-02 9.40125845e-01]]\n",
      "actual y:  [1 0 1 0 1]\n",
      "y predictions:  [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "print(ypp)\n",
    "print(\"actual y: \", data.test_y)\n",
    "print(\"y predictions: \",yp)\n",
    "\n",
    "for i in range(len(ypp)):\n",
    "    if ypp[i][1] > 0.5:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72790cc2-6031-420f-9f32-f03f705d9150",
   "metadata": {},
   "source": [
    "Results and Discussion/Conclusion:\n",
    "\n",
    "To recap the results, the AUC in the ROC plot was 0.833 meaning that the true positive rate is generally higher than the false positive rate, the precision was 1.0 meaning that the model's predictions of wins always match the actual outcome, the recall was 0.666 meaning that the model's predictions of wins are only 66.66% of all the actual win outcomes, the accuracy was 0.8 meaning that the outcome predicted is 80% correct.\n",
    "\n",
    "What I learned was the considerations that are needed to take when selecting features for logistic regression classification. Using the correlation matrix was a needed step that I almost forgot to include when considering collinearity and how much some features were correlated with another. At first I did not consider this and the model overfitted, causing the AUC to be at 1.0 but after adjusting the features by dropping some, the AUC and other metrics seemed more realistic. \n",
    "\n",
    "Something that did not work was trying to include every feature from the raw data into training the model. As mentioned earlier, it led to overfitting and an unrealistic performance metrics. \n",
    "\n",
    "One way to improve is to perhaps wait later on in the season when there are more games to be samples in the dataset. This will help reduce overfitting and will give a more accurate way to measure performance. Another way to improve is to consider more features that are not related to the game box score such as players available at each game, minutes of star players, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5651696-e5e9-4305-a1b8-36004075535d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
